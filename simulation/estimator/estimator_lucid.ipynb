{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lucid: Workload Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import preprocessing, metrics\n",
    "from interpret.glassbox import ExplainableBoostingRegressor\n",
    "\n",
    "\n",
    "sns.set_style(\"ticks\")\n",
    "font = {\n",
    "    \"font.family\": \"Roboto\",\n",
    "    \"font.size\": 12,\n",
    "}\n",
    "sns.set_style(font)\n",
    "paper_rc = {\n",
    "    \"lines.linewidth\": 3,\n",
    "    \"lines.markersize\": 10,\n",
    "}\n",
    "sns.set_context(\"paper\", font_scale=1.8, rc=paper_rc)\n",
    "current_palette = sns.color_palette()\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "idx = 0\n",
    "save = False\n",
    "experiment_list = [\"Venus_Sept\", \"Saturn_Sept\", \"Philly\"]\n",
    "cluster_list = [\"Venus\", \"Saturn\", \"Philly\"]\n",
    "cluster = cluster_list[idx]\n",
    "experiment = experiment_list[idx]\n",
    "\n",
    "datapath = f\"../data/{cluster}\"\n",
    "\n",
    "\n",
    "result = pd.DataFrame()\n",
    "if cluster == \"Philly\":\n",
    "    df = pd.read_csv(\n",
    "        f\"{datapath}/cluster_full_log.csv\",\n",
    "        parse_dates=[\"submit_time\"],\n",
    "        usecols=[\n",
    "            \"job_id\",\n",
    "            \"user\",\n",
    "            \"vc\",\n",
    "            \"gpu_num\",\n",
    "            \"submit_time\",\n",
    "            \"amp\",\n",
    "            \"gpu_util\",\n",
    "            \"gmem_util\",\n",
    "            \"gmem\",\n",
    "            \"duration\",\n",
    "        ],\n",
    "    )\n",
    "else:\n",
    "    df = pd.read_csv(\n",
    "        f\"{datapath}/cluster_full_log.csv\",\n",
    "        parse_dates=[\"submit_time\"],\n",
    "        usecols=[\n",
    "            \"job_id\",\n",
    "            \"user\",\n",
    "            \"vc\",\n",
    "            # \"jobname\",\n",
    "            \"gpu_num\",\n",
    "            \"cpu_num\",\n",
    "            \"submit_time\",\n",
    "            \"month\",\n",
    "            \"day\",\n",
    "            \"hour\",\n",
    "            \"dayofweek\",\n",
    "            \"amp\",\n",
    "            \"gpu_util\",\n",
    "            \"gmem_util\",\n",
    "            \"gmem\",\n",
    "            \"duration\",\n",
    "        ],\n",
    "    )\n",
    "\n",
    "if cluster == \"Philly\":\n",
    "    trace_range = (\"2017-10-01 00:00:00\", \"2017-10-07 23:59:00\")\n",
    "    train_df = df[(df[\"submit_time\"] > trace_range[1])]\n",
    "    val_df = df[(df[\"submit_time\"] >= trace_range[0]) & (df[\"submit_time\"] <= trace_range[1])]\n",
    "else:\n",
    "    # trace_range = (\"2020-09-01 00:00:00\", \"2020-09-26 23:59:59\")\n",
    "    trace_range = (\"2020-09-01 00:00:00\", \"2020-09-27 00:10:00\")  # Add a bit more job for prediction\n",
    "    train_df = df[(df[\"submit_time\"] < trace_range[0])]\n",
    "    val_df = df[(df[\"submit_time\"] >= trace_range[0]) & (df[\"submit_time\"] <= trace_range[1])]\n",
    "\n",
    "\n",
    "train_df = train_df.sort_values(by=\"submit_time\")\n",
    "train_df.reset_index(inplace=True, drop=True)\n",
    "val_df = val_df.sort_values(by=\"submit_time\")\n",
    "val_df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "train_data = train_df.drop(columns=[\"duration\", \"submit_time\"])\n",
    "test_data = val_df.drop(columns=[\"duration\", \"submit_time\"])\n",
    "train_label = train_df[[\"duration\"]]\n",
    "test_label = val_df[[\"duration\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weekly Update Lucid Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Len: 89556\n",
      "mae_score: 14435.39, mape_score: 184.21, r2_score: 0.4339\n",
      "Train Data Len: 94471\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 27\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain Data Len: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(train_data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     26\u001b[0m ebm \u001b[38;5;241m=\u001b[39m ExplainableBoostingRegressor(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m, interactions\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m)\n\u001b[0;32m---> 27\u001b[0m \u001b[43mebm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_label\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m pred \u001b[38;5;241m=\u001b[39m ebm\u001b[38;5;241m.\u001b[39mpredict(test_data)\n\u001b[1;32m     30\u001b[0m mae_score \u001b[38;5;241m=\u001b[39m metrics\u001b[38;5;241m.\u001b[39mmean_absolute_error(test_label, pred)\n",
      "File \u001b[0;32m/opt/conda/envs/lucid/lib/python3.9/site-packages/interpret/glassbox/_ebm/_ebm.py:1395\u001b[0m, in \u001b[0;36mEBMModel.fit\u001b[0;34m(self, X, y, sample_weight, bags, init_score)\u001b[0m\n\u001b[1;32m   1348\u001b[0m         early_stopping_rounds_local \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   1350\u001b[0m     parallel_args\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m   1351\u001b[0m         (\n\u001b[1;32m   1352\u001b[0m             dataset,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1392\u001b[0m         )\n\u001b[1;32m   1393\u001b[0m     )\n\u001b[0;32m-> 1395\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mprovider\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mboost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1397\u001b[0m \u001b[38;5;66;03m# allow python to reclaim these big memory items via reference counting\u001b[39;00m\n\u001b[1;32m   1398\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m parallel_args  \u001b[38;5;66;03m# this holds references to dataset, scores_bags, and bags\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/lucid/lib/python3.9/site-packages/interpret/provider/_compute.py:20\u001b[0m, in \u001b[0;36mJobLibProvider.parallel\u001b[0;34m(self, compute_fn, compute_args_iter)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mparallel\u001b[39m(\u001b[38;5;28mself\u001b[39m, compute_fn, compute_args_iter):\n\u001b[0;32m---> 20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompute_fn\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcompute_args_iter\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/lucid/lib/python3.9/site-packages/joblib/parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/lucid/lib/python3.9/site-packages/joblib/parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/lucid/lib/python3.9/site-packages/joblib/parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trace_range_list = [\n",
    "    (\"2020-09-01 00:00:00\", \"2020-09-07 00:00:00\"), # Week 1\n",
    "    (\"2020-09-07 00:00:00\", \"2020-09-14 00:00:00\"), # Week 2\n",
    "    (\"2020-09-14 00:00:00\", \"2020-09-21 00:00:00\"), # Week 3\n",
    "    (\"2020-09-21 00:00:00\", \"2020-09-27 00:10:00\"), # Week 4\n",
    "]\n",
    "week_df = pd.DataFrame()\n",
    "for trace_range in trace_range_list:\n",
    "\n",
    "    train_df = df[(df[\"submit_time\"] < trace_range[0])]\n",
    "    val_df = df[(df[\"submit_time\"] >= trace_range[0]) & (df[\"submit_time\"] <= trace_range[1])]\n",
    "\n",
    "\n",
    "    train_df = train_df.sort_values(by=\"submit_time\")\n",
    "    train_df.reset_index(inplace=True, drop=True)\n",
    "    val_df = val_df.sort_values(by=\"submit_time\")\n",
    "    val_df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "    train_data = train_df.drop(columns=[\"duration\", \"submit_time\"])\n",
    "    test_data = val_df.drop(columns=[\"duration\", \"submit_time\"])\n",
    "    train_label = train_df[[\"duration\"]]\n",
    "    test_label = val_df[[\"duration\"]]\n",
    "\n",
    "    print(f\"Train Data Len: {len(train_data)}\")\n",
    "\n",
    "    ebm = ExplainableBoostingRegressor(learning_rate=0.01, interactions=20)\n",
    "    ebm.fit(train_data, train_label)\n",
    "    pred = ebm.predict(test_data)\n",
    "\n",
    "    mae_score = metrics.mean_absolute_error(test_label, pred)\n",
    "    mape_score = metrics.mean_absolute_percentage_error(test_label, pred)\n",
    "    r2_score = metrics.r2_score(test_label, pred)\n",
    "    result.at[\"ebm_r2\", cluster] = r2_score\n",
    "    print(f\"mae_score: {mae_score:.2f}, mape_score: {mape_score:.2f}, r2_score: {r2_score:.4f}\")\n",
    "\n",
    "    pred = pred.astype(int)\n",
    "    val_df.loc[:,'priority'] = pred\n",
    "    week_df = pd.concat([week_df, val_df])\n",
    "# week_df.to_csv(f\"ebm/{experiment}_Sept_ebm_weekly_updated.csv\", index=False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Job Name Affinity Propagation\n",
    "\n",
    "Scripts below need original jobname information, which cannot release"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import distance\n",
    "import time\n",
    "import warnings\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import groupby\n",
    "from sklearn.cluster import AffinityPropagation\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "top_high_freq_num = 100\n",
    "\n",
    "idx = 1\n",
    "experiment_list = [\"Venus_Sept\", \"Saturn_Sept\", \"Philly\"]\n",
    "cluster_list = [\"Venus\", \"Saturn\", \"Philly\"]\n",
    "cluster = cluster_list[idx]\n",
    "experiment = experiment_list[idx]\n",
    "\n",
    "df = pd.read_csv(f'../data/{cluster}/cluster_full_log.csv',\n",
    "                 parse_dates=['submit_time', 'start_time', 'end_time'])\n",
    "\n",
    "df = df[df['gpu_num']>0]\n",
    "df.drop(columns=['year', 'nodelist', 'priority', 'minute'], inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "count = df['jobname'].value_counts()\n",
    "name_list = list(count.index)\n",
    "\n",
    "high_freq = name_list[:top_high_freq_num]\n",
    "to_cluster = name_list[top_high_freq_num:]\n",
    "to_cluster.sort()\n",
    "\n",
    "groups = [list(g) for k, g in groupby(to_cluster, key=lambda x: x[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = {}\n",
    "\n",
    "for group in groups:\n",
    "    if len(group) == 1:\n",
    "        label_dict.update({group[0]:group[0]})\n",
    "    else:\n",
    "        print(f\"Processing First Character: {group[0][0]}, Lenth: {len(group)}\")\n",
    "        ts = time.time()\n",
    "\n",
    "        names = np.asarray(group)\n",
    "        lev_similarity = -1 * np.array([[distance.levenshtein(w1, w2) for w1 in names] for w2 in names])\n",
    "\n",
    "        affprop = AffinityPropagation(affinity=\"precomputed\", damping=0.9, random_state=6)\n",
    "        affprop.fit(lev_similarity)\n",
    "\n",
    "        for cluster_id in np.unique(affprop.labels_):\n",
    "            exemplar = names[affprop.cluster_centers_indices_[cluster_id]]\n",
    "            cluster = np.unique(names[np.nonzero(affprop.labels_==cluster_id)])\n",
    "\n",
    "            for ori in cluster:\n",
    "                label_dict.update({ori:exemplar})\n",
    "\n",
    "        print(f\"Time Cost: {time.time()-ts} s\")\n",
    "\n",
    "for i in high_freq:\n",
    "    label_dict.update({i:i})\n",
    "assert len(label_dict) == len(name_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Replace Name\"\"\"\n",
    "for i in range(len(df)):\n",
    "    df.at[i, 'jobname'] = label_dict[df.at[i, 'jobname']]\n",
    "\n",
    "df.to_csv(f\"./{cluster}/cluster_full_log.csv\", index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lucid",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
